{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#what-is-disk","title":"What is DISK","text":"<p>DISK is a framework that uses AI to automate scientific data analysis to accelerate discoveries. There are many large repositories of scientific data could be continuously and systematically analyzed by DISK, updating findings and potentially making new discoveries as new data becomes available.</p> <p>This video shows a brief overview how a new hypothesis can be specified by a user and the automation that follows.</p> <p></p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>You can start to use DISK here, note that you will need to request an account.</p>"},{"location":"#target-users-and-documentation","title":"Target Users and Documentation","text":"<ul> <li>Users: Scientists who use DISK to specify and test hypotheses or ask questions.  Read this documentation</li> <li>Advanced Users: Scientists who understand the design of DISK and can extend it to support new types of hypotheses and questions by defining data queries and workflows.  Here is the detailed documentation. </li> <li>Developers: Programmers who can extend DISK by integrating it with new data sources and new workflow systems.  There is documentation and a GitHub repository with the code.</li> </ul>"},{"location":"#how-disk-works","title":"How DISK Works","text":"<p>DISK automatically tests hypotheses provided by a scientist. To do this, DISK retrieves data from existing data repositories and analyzes the data using intelligent workflows. User-defined hypotheses are re-run when new data or methods become available.  DISK stores all the provenance and metadata for new results, so they can be inspected and reproduced.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>User interface to specify scientific hypotheses and track results</li> <li>Automated retrieval of data relevant to a given hypothesis or question</li> <li>Automated selection and execution of workflows to analyze data</li> <li>Automated recording of provenance for new results</li> <li>Support for new data source integration using Adapters</li> <li>Support for new workflow engines using Adapters</li> <li>SSO for user authentication</li> </ul>"},{"location":"#overview-of-disk-architecture","title":"Overview of DISK Architecture","text":"<p>For more information about the DISK architecture, please check the architecture page.</p>"},{"location":"#development-status","title":"Development Status","text":"<p>DISK is being actively developed by the USC/ISI Knowledge Capture and Discovery Team. DISK releases can be found releases.</p>"},{"location":"#applications-of-disk","title":"Applications of DISK","text":"<p>We are using DISK in several applications, more details can be found here.</p>"},{"location":"concepts/","title":"Core Concepts in DISK","text":"<ul> <li>Hypothesis: A hypothesis statement is a set of assertions about entities that can be tested. A hypothesis can be tested by analyzing relevant data.</li> <li>Question: A statement that represents the goal of a scientific investigation.</li> <li>Hypothesis or Question Template:  A general pattern that can be instantiated to create a particular hypothesis or question.  </li> <li>Workflow:  Workflows specify multi-step computations to carry out a type of data analysis.</li> <li>Method: A general approach that is followed to test a hypothesis.  </li> <li>Line of Inquiry (LOI): DISK represents in an LOI how a hypothesis will be tested through a computational experiment. An LOI specifies: 1) A hypothesis template, 2) A query to retrieve relevant data from accessible data sources in DISK, 3) One or more workflows to analyze the data retrieved from the query, and 4) A meta-workflow to combine the results of all the workflows and synthesize findings.  </li> <li>Triggered Line of Inquiry: When the user specifies a hypothesis, it is matched against the hypothesis templates of all LOIs.  The matched LOI is then triggered for execution.  </li> <li>Provenance: DISK records the provenance of all results so that they can be inspected and reproduced. </li> <li>Metadata: DISK accesses data sources that contain datasets that are well described with appropriate metadata that can be used in specifying queries.</li> </ul> <p>The diagram below gives an overview of the differtent components of DISK and how different types of users interact with DISK.</p> <p></p>"},{"location":"admin-guide/","title":"Overview","text":"<p>This guide is for Administrators who need to set up a new DISK installation.</p> <p>Note</p> <p>Please make sure you have completed the User guide and the Advanced User guide before you start.</p>"},{"location":"admin-guide/configuration/","title":"Configuration","text":"<p>To configure DISK, you need to edit the server.properties file.</p>"},{"location":"admin-guide/configuration/#editing-serverproperties-configuration-file","title":"Editing server.properties configuration file","text":"<p>The configuration contains four major sections:</p> <ul> <li>Data Adapters: This section contains the list of data adapters that are used to retrieve data from the data sources.</li> <li>Method Adapters: This section contains the list of method adapters that are used to run workflows for data analysis.</li> <li>Question Templates: This section contains the list of question templates that are used to create new questions.</li> <li>Vocabularies: This section contains the list of ontologies that are used to describe the domain.</li> </ul>"},{"location":"admin-guide/configuration/#data-adapters","title":"Data Adapters","text":"<p>To add a new Data Source, you should edit the section <code>data-adapters</code>. The supported data-adapters are available here.</p> <p>For example, the sparql adapter requires the following attributes</p> <ul> <li>type: sparql</li> <li> <p>endpoint: the URL where the RDF data source is available If the endpoint server is protected using HTTP Basic Authentication</p> </li> <li> <p>username: the username  </p> </li> <li>username: the password</li> </ul> <pre><code>data-adapters = {\nWiki = {\ntype = sparql;\nendpoint = https://endpoint.mint.isi.edu/tutorial;\nusername = admin;\npassword = admin;\n}\n}\n</code></pre>"},{"location":"admin-guide/configuration/#method-adapters","title":"Method Adapters","text":"<p>To add a new workflow system, you should edit the section <code>method-adapters</code>. The supported method-adapters are available here.</p> <p>For example, the wings adapter requires the following attributes</p> <pre><code>method-adapters =\n{\nwings =\n{\ntype = wings;\nendpoint = http://localhost:7080/wings-portal;\nusername = admin;\npassword = 4dm1n!23;\ninternal_server = http://wings:8080/wings-portal;\ndomain = test;\n}\n}\n</code></pre>"},{"location":"admin-guide/configuration/#question-templates","title":"Question Templates","text":"<p>If you want to use a new Question Templates, you should edit the section <code>question-templates</code>. To learn more about question templates, please visit here.</p> <p>The following example shows how to add the Bike-Rental example on DISK.</p> <pre><code>question-templates =\n{\nbikes = https://raw.githubusercontent.com/KnowledgeCaptureAndDiscovery/QuestionOntology/main/examples/bike_rent.xml;\n}\n</code></pre>"},{"location":"admin-guide/configuration/#domain-vocabularies","title":"Domain vocabularies","text":"<p>If you want to use a new domain vocabulary, you should edit the section <code>vocabularies</code>. To learn more about how to create or edit vocabularies, please visit [insert link].</p> <p>The following example shows how to add the Neuro-DISK domain vocabulary on DISK.</p> <pre><code>vocabularies =\n{\nneuro = {\nurl = https://knowledgecaptureanddiscovery.github.io/DISK-Ontologies/enigma_hypothesis/release/2.0.1/ontology.ttl;\nprefix = neuro;\nnamespace = https://w3id.org/disk/ontology/enigma_hypothesis#;\ndescription = \"The NEURO-DISK Hypothesis Ontology: Defines terms to express neuroimaging hypotheses.\";\n}\n}\n</code></pre>"},{"location":"admin-guide/configuration/#restarting-disk","title":"Restarting DISK","text":"<p>DISK needs to be restart after you have edited the configuration files.</p> <p>To restart the DISK, you should run the following command:</p> <pre><code>docker-compose restart\n</code></pre>"},{"location":"admin-guide/installation/","title":"Installation","text":"<p>You can install DISK using a Docker container or building from source code. We recommend to use a Docker container to install DISK. </p>"},{"location":"admin-guide/installation/#requirements","title":"Requirements","text":"<p>To install DISK from a Docker container you need to meet the following requirements:</p> <ul> <li>Docker</li> <li>Docker Compose</li> <li>Operating System: Linux, macOS, Windows</li> <li>Architecture: x86_64</li> <li>Memory: 2GB</li> <li>CPU: 1 core</li> </ul>"},{"location":"admin-guide/installation/#installation-process","title":"Installation process","text":"<p>Clone the repository using git:</p> <pre><code>$ git clone https://github.com/KnowledgeCaptureAndDiscovery/DISK-WEB.git\n</code></pre> <p>Install the DISK container using <code>docker-compose</code> tool:</p> <pre><code>$ docker-compose up -d\n</code></pre> <p>Now you can verify if DISK is running:</p> <pre><code>$ docker-compose ps\n</code></pre> <p>This will generate the following output:</p> <pre><code>     Name                    Command               State                    Ports                  \n---------------------------------------------------------------------------------------------------\ncore_backend_1    catalina.sh run                  Up      0.0.0.0:8080-&gt;8080/tcp,:::8080-&gt;8080/tcp\ncore_endpoint_1   /docker-entrypoint.sh java ...   Up      0.0.0.0:3030-&gt;3030/tcp,:::3030-&gt;3030/tcp\ncore_frontend_1   nginx -g daemon off;             Up      0.0.0.0:8000-&gt;80/tcp,:::8000-&gt;80/tcp    \ncore_wings_1      catalina.sh run                  Up      0.0.0.0:7080-&gt;8080/tcp,:::7080-&gt;8080/tcp\n</code></pre> <p>If the state is <code>Up</code> in all the lines, all the DISK services are running.</p> <p>You can access the DISK user interface at http://localhost:8000.</p>"},{"location":"admin-guide/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"admin-guide/installation/#check-the-server","title":"Check the server","text":"<p>Sometimes the server is not responding. You can check the state of the server opening http://localhost:8080/disk-server/vocabulary. It might take a little while to open it for the first time as it downloads domain vocabularies from the internet.</p> <p>You should see a list of domain vocabularies.</p>"},{"location":"advanced-user-guide/","title":"Overview","text":"<p>This documentation is for Advanced Users who want to create new Lines of Inquiry and new kinds of hypotheses and questions in DISK.</p> <p>Advanced users should have basic familiarity with ontologies, OWL, SPARQL, and RDF.  </p> <p>Note</p> <p>This documentation assumes that you are familiar with the basic DISK concepts and User Guide.</p>"},{"location":"advanced-user-guide/running-workflows/","title":"Running workflows","text":"<p>DISK can execute workflows on different workflows systems as long as a method adapter is available. Each LOI defines how any parameters and data obtained as result of the data query will be used when creating one or more workflow executions. The outputs and metadata generated on this process is stored as a TLOI.</p> <p>Additionally, A LOI can define a meta workflow to run using as input the result of the workflow executions.</p>"},{"location":"advanced-user-guide/running-workflows/#wings","title":"Wings","text":"<p>To learn how to run workflows on Wings, please check the Wings documentation.</p>"},{"location":"advanced-user-guide/questions/disk-ontologies/","title":"Ontologies used in DISK","text":"<p>DISK uses several ontologies to represent core concepts about hypothesis-driven discoveries, shown in the following diagram:</p> <p></p> <ul> <li> <p>Community ontologies (shown in blue): Widely-used community standards to represent basic entities such as people, provenance, and files. These ontologies are the core vocabulary used to store general metadata on DISK.</p> </li> <li> <p>Core DISK ontologies (shown in green): Internal ontologies that represent core knowledge structures in DISK, such as:</p> <ul> <li> <p>DISK Ontology: Basic DISK definitions such as Hypothesis and Line of inquiry. More information here.</p> </li> <li> <p>DISK Hypothesis Ontology: Basic properties to define general hypothesis. More information here.</p> </li> <li> <p>Question Template Ontology: Ontology to represent questions. More information here.</p> </li> </ul> </li> <li> <p>Imported Ontologies (shown in yellow): Imported ontologies. Categorized on three types:</p> <ul> <li> <p>Data Ontologies: Each data repository used in DISK has to provide an ontology of its metadata concepts. This ontology is specified as part of Data Adapters.</p> </li> <li> <p>Workflow System Ontologies: Each workflow system used in DISK has to provide an ontology of its workflow concepts.  This ontology is a key aspect of Method Adapters.</p> </li> <li> <p>Domain Ontologies: These are ontologies that are used to state hypotheses and questions.  They are domain specific.</p> </li> </ul> </li> </ul>"},{"location":"advanced-user-guide/questions/extending-ontology/","title":"Extending the Questions Ontology","text":"<p>The Scientific Questions Ontology defines core concepts to express scientific question templates, question variables, options, and constraints.</p> <p>We show here with simple examples how to use an ontology editor to add new types of questions to DISK.  </p>"},{"location":"advanced-user-guide/questions/extending-ontology/#setting-up-an-ontology-editor","title":"Setting Up an Ontology Editor","text":"<p>We recommend using the Prot\u00e9g\u00e9 ontology editor.  Extensive documentation about how to install Prot\u00e9g\u00e9 is available here.</p> <p>Load into Prot\u00e9g\u00e9 the DISK Scientific Questions Ontology:</p> <ol> <li>Open Prot\u00e9g\u00e9</li> <li>Click the \"+\" button next to the \"Direct Imports\" section. </li> <li>A new window will be opened</li> <li>Paste the DISK Scientific Qquestions Ontology URL in the text field <code>https://knowledgecaptureanddiscovery.github.io/QuestionOntology/release/v1.0.0/ontology.xml</code></li> </ol> <p></p> <p>Great. You are all set to extend the ontology with new types of questions.</p>"},{"location":"advanced-user-guide/questions/extending-ontology/#designing-new-types-of-question","title":"Designing New Types of Question","text":"<p>In this step, we will learn how to transfer your question into the ontology</p> <p>Suppose that our users want to predict the number of bike rentals in a bike sharing service from the weather forecast in an area.  A user may hypothesize that in New York bike rentals can be predicted from temperature, humidity, and precipitation.  But in Seattle the temperature, BP, and precipitation may be the most important factors, while in Chicago it may be temperature, wind, and precipitation.  So we wan to add a new type of question:</p> <p>Is the number of rented bikes associated with ?weatherSensor1, ?weatherSensor2, and ?weatherSensor3 in ?region ?</p> <p>We refer to this statement as the Question Statement.  Question statements contain Question Variables.  In this example, the question variables are ?weatherSensor1, ?weatherSensor2, ?weatherSensor3, and ?region.</p> <p>To create this new type of question, we have to define 3 new items in the ontology:</p> <ol> <li>Question Statement: It is the statement of the question template in English as in the example above.</li> <li>Question Variables: It represents the variables used on a Question Statement.</li> <li>Question Template: It is the concept that represents both the Question Statement and the Question Variables.</li> </ol>"},{"location":"advanced-user-guide/questions/extending-ontology/#creating-the-question-statement-in-the-ontology","title":"Creating the Question Statement in the Ontology","text":"<p>In this example, we will create our question: </p> <p><code>Can we predict the number of rented bikes using 3 climate variables?</code></p> <p>To create a new question</p> <ol> <li>Go to the tab Individuals by class</li> <li>Select the class Question under <code>owl:Thing</code></li> <li>Create a new Individual</li> </ol> <p></p> <p>And each question must have a label (description) which will be used to select your question in the UI.</p> <p>To add the label, </p> <ol> <li>go to the annotations panel and click the + button,</li> <li>Select the <code>rdfs:label</code> property</li> <li>Add the description of your question. </li> </ol> <p></p>"},{"location":"advanced-user-guide/questions/extending-ontology/#create-the-question-variables","title":"Create the Question Variables","text":"<p>A Question Variable represents a variable used on a Question. </p> <p>To create a new question</p> <ol> <li>Go to the tab Individuals by class</li> <li>Select the class QuestionVariable under <code>owl:Thing</code></li> <li>Create a new Individual</li> <li>Select a unique ID for your question variable</li> </ol> <p></p> <p>On the property assertion panel, </p> <ol> <li>Click on the + button to the right of Data property assertions.  A new window will be open</li> <li>Fill the properties <code>Has variable name</code> and either <code>Has constraints</code> or <code>Has fixed options</code>.</li> </ol> <p></p> <p>Next, we need to link the question with the Variables used in it. </p> <ol> <li>Go to the class Question </li> <li>Select the question you created in step 4 </li> <li>Click the <code>+</code>  button to the right of Object property assertions.</li> <li>On the modal you must select the property <code>Has question variable</code> and the question variable to link.</li> </ol> <p></p>"},{"location":"advanced-user-guide/questions/extending-ontology/#create-the-question-template","title":"Create the Question Template","text":"<p>A Question Template is a text representation of the question that will create a form that the user must fill. All \"question variable\" names used on this template will be replaced for inputs with constraints.</p> <p>To create it, we will follow the next steps</p> <ol> <li>On the property assertion panel, click on the + button to the right of Data property assertions. </li> <li>In this menu, you must define values for <code>Has question template</code> and <code>Has Question pattern</code> properties. The question template will be used to generate a form allowing users further customization of questions. Each variable written on the question template will be replaced for a select input with relevant options. The question pattern is the RDF representation of this question. Is a set of RDF triples, but you can write your question variables on it. When a user set values for a question, this RDF representation will be updated for the values selected by the user.</li> </ol> <p></p>"},{"location":"advanced-user-guide/questions/extending-ontology/#verification","title":"Verification","text":"<p>You did it! Let\u2019s do a verification of your work.</p> <p>The end result should be an ontology like the following.</p>"},{"location":"advanced-user-guide/questions/extending-ontology/#question-variables","title":"Question variables","text":"<ol> <li>Go to the Individuals by class tab </li> <li>Click the Question class</li> </ol> <p>You should see two properties called: Has Fixed Options and Has Variable Name</p> <p></p>"},{"location":"advanced-user-guide/questions/extending-ontology/#questions","title":"Questions","text":"<ol> <li>Go to the Individuals by class tab </li> <li>Click the Question class</li> </ol> <p>You should see:</p> <ul> <li>the three variables: ClimateVariable1, ClimateVariable2 and ClimateVariable3</li> <li>the property <code>Has Question Pattern</code> and <code>Has Question Template</code></li> </ul> <p></p>"},{"location":"advanced-user-guide/questions/extending-ontology/#save-the-ontology","title":"Save the ontology","text":"<p>Click the <code>File</code> menu and <code>Save as</code> </p> <p></p> <p>Save the ontology using the <code>OWL/XML syntax</code></p> <p></p> <p>You did it. You can use your ontology on DISK! Please go to Using DISK documentation to learn how to use it</p>"},{"location":"advanced-user-guide/questions/overview/","title":"Creating New Questions","text":"<p>DISK questions and hypotheses use terms from the DISK Scientific Questions ontology.  This ontology represents the question types that users take as a starting point to create their own specific questions.  A question type is represented as a Question Template that includes Question Variables.  The Question Variables are placeholders for the specific objects in a user's questions.</p> <p>Three steps are required to extend DISK with new kinds of questions:</p> <ol> <li>Add a new Question Template to the ontology.</li> <li>Add the Question Variables for the Question Template to the ontology.</li> <li>Publish the updated ontology.</li> </ol> <p>In the following sections, we will introduce the ontologies used in DISK and describe how to extend the DISK Scientific Questions ontology.</p>"},{"location":"advanced-user-guide/questions/question-ontology/","title":"Scientific Questions Ontology","text":"<p>The DISK Scientific Questions Ontology provides a vocabulary to create semantic representations for scientific hypothesis or questions.</p> <p>The ontology defines the <code>Question</code> class, with the following properties:</p> <ul> <li> <p><code>hasQuestionTemplate</code>: A brief text statement of the question. Includes Question Variables that will be replaced with domain concepts to create specific questions.</p> </li> <li> <p><code>hasQuestionPattern</code>: <code>SPARQL</code> like semantic representation of this Question, placing Question Variables within the Question Template.</p> </li> <li> <p><code>hasQuestionVariable</code>: list of <code>QuestionVariable</code> for this Question template. These appear as <code>SPARQL</code> variables on the Question Pattern.</p> </li> </ul> <p>The <code>QuestionVariable</code> class has the following properties:</p> <ul> <li> <p><code>hasVariableName</code>: <code>SPARQL</code> name of this variable. It is used on the Question Pattern.</p> </li> <li> <p><code>hasConstraints</code>: <code>SPARQL</code> query that will determine any restrictions for this variable.</p> </li> <li> <p><code>hasFixedOptions</code>: list of possible values for this variable.  This is an alternative to specifying <code>hasConstraints</code>.</p> </li> </ul> <p>Since each question corresponds to a portion of a <code>SPARQL</code> query, multiple questions can be composed to create more complex ones.</p>"},{"location":"advanced-user-guide/steps/add-basic-info/","title":"Creating a New Line of Inquiry","text":"<p>You can create a new Line of Inquiry (LOI) by selecting the Create Line of Inquiry button.</p> <p>We show first how to create an additional LOI for a question template that already exists.  There can be several LOIs to address the same question template, for example each LOI can specify an analysis for a different type of data that can answer the same question.</p> <p>We will show later how to create new question templates.</p>"},{"location":"advanced-user-guide/steps/add-basic-info/#adding-basic-documentation","title":"Adding Basic Documentation","text":"<p>You can fill the form to provide basic documentation about the LOI:</p> <ul> <li>Line of Inquiry name: A meaningful name for the Line of Inquiry.</li> <li>Line of Inquiry description: A brief overview of what the Line of Inquiry is for and how it works.</li> </ul>"},{"location":"advanced-user-guide/steps/add-basic-info/#selecting-the-question","title":"Selecting the Question","text":"<p>A Line of Inquiry is created to answer a type of question and therefore it must specify a Question Template.</p> <p>You can display the question templates available by selecting the Select Question drop down list. Then, select a question from the list.</p> <p></p>"},{"location":"advanced-user-guide/steps/add-basic-info/#question-variables","title":"Question Variables","text":"<p>Note that each question template has one or more question variables. These question variables will be used in the data query that you will create for the LOI as we will explain next. </p>"},{"location":"advanced-user-guide/steps/add-basic-info/#next-step","title":"Next step","text":"<p>In the next step, you will write a data query to obtain the data needed to answer the type of question that this LOI is designed to answer.</p>"},{"location":"advanced-user-guide/steps/specify-workflow/","title":"Specifying Workflows and Meta-Workflows","text":"<p>When an LOI is edited then a list of possible workflows will be shown and you can choose one</p> <p>To specify the workflow of the LOI, you need to select the button Add Workflow and select the workflow from the list of workflows.</p> <p></p>"},{"location":"advanced-user-guide/steps/specify-workflow/#passing-data-to-the-workflow","title":"Passing Data to the Workflow","text":"<p>When you select a workflow, DISK displays the Workflow Inputs required to run.</p> <p>For example, the following workflow requires the inputs to run:</p> <ul> <li><code>?WeatherSensorCsvFile</code> a CSV file or multiple CSV files containing the weather data</li> <li><code>?WeatherVariable1</code>,<code>?WeatherVariable2</code>,<code>?WeatherVariable3</code> the names of the weather variables to be used in the workflow. (e.g. temperature, wind speed or precipitation)</li> </ul> <p></p> <p>Next, you need to specify the values for the Workflow Inputs. To do that, click on one of the Workflow Inputs and select the Data Query or Hypothesis variable from the list displayed.</p> <p>Info<p>The Data Query variables are obtained from the data query response and the question template.</p> </p> <p>For example, we select the following options:</p> <ul> <li>Hypothesis variable<code>?WeatherSensor1</code> to pass as the value for the <code>?WeatherSensor1</code> Workflow Input.</li> <li>Hypothesis variable <code>?WeatherSensor2</code> to pass as the value for the <code>?WeatherSensor2</code> Workflow Input.</li> <li>Hypothesis variable <code>?WeatherSensor3</code> to pass as the value for the <code>?WeatherSensor3</code> Workflow Input.</li> <li>Data Query variable <code>?WeatherRecordCsvFile</code> to pass as the value for the <code>?WeatherCsvFile</code> Workflow Input. Also, we select the option called Multiple because the Data Query or Hypothesis variable <code>?url</code> can be a CSV file or multiple CSV files.</li> </ul> <p></p> <p>You can also add a Meta-Workflow to the workflow.  A Meta-Workflow is a workflow that is executed after the main workflow. </p>"},{"location":"advanced-user-guide/steps/specify-workflow/#saving","title":"Saving","text":"<p>Remember to save the Line of Inquiry.</p>"},{"location":"advanced-user-guide/steps/specify-workflow/#next-steps","title":"Next steps","text":"<p>You can test the LOI by creating a new Hypothesis and selecting the LOI. See the previous section.</p>"},{"location":"advanced-user-guide/steps/write-query/","title":"Writing a Data Query for an LOI","text":"<p>A data query is used to obtain the data required to answer the question template of the LOI.</p> <p>Note</p> <p>The data query will be executed on an external data repository that has a data adapter that integrates it with DISK. The current implementation of DISK supports queries for data using <code>SPARQL</code> as the query language. Developers can extend DISK to integrate new data sources and create new data adapters.</p>"},{"location":"advanced-user-guide/steps/write-query/#writing-a-data-query-in-sparql","title":"Writing a Data Query in SPARQL","text":"<p>The starting point of the query are the Question Variables specified in the Question Template.  </p> <p>You can write the query by clicking on the Query text area.</p> <p></p> <p>The next example shows a data query for neuroscience data.  The query follows several steps to obtain the data:</p> <ol> <li>Using the Question Variable <code>?Genotype</code> to find the <code>?Cohort</code></li> <li>Using <code>?Cohort</code> to find the <code>?dataset</code></li> <li>Using <code>?dataset</code> to find the <code>?schema</code></li> <li>Using <code>?schema</code> to find <code>?url</code></li> </ol> <p>The query also includes at the end the Workflow Variable: Url that is passed as an input to the workflow of the LOI, as we describe next.</p> <p></p>"},{"location":"advanced-user-guide/steps/write-query/#specifying-workflows-and-meta-workflows","title":"Specifying Workflows and Meta-Workflows","text":"<p>To specify the workflow of the LOI, you need to select the button Add Workflow and select the workflow from the list of workflows.</p> <p></p>"},{"location":"advanced-user-guide/steps/write-query/#next-steps","title":"Next steps","text":"<p>In the next section, you will learn how to select workflows and select the workflow inputs.</p>"},{"location":"advanced-user-guide/workflows/bike-example/","title":"Bikes example on Wings","text":"<p>In this step, we will learn how to create a workflow using Wings.</p> <p>Suppose that our users want to predict the number of bike rentals in a bike sharing service from the weather forecast in an area. A user may hypothesize that in New York bike rentals can be predicted from temperature, humidity, and precipitation. But in Seattle the temperature, BP, and precipitation may be the most important factors, while in Chicago it may be temperature, wind, and precipitation. So we wan to add a new type of question:</p> <p>Is the number of rented bikes associated with ?weatherSensor1, ?weatherSensor2, and ?weatherSensor3 in ?region ?</p> <p>This question can be answer by a simple lineal regression and you can find the code in the following Link The code is a simple Python script that reads the weather data from one or multiple CSV files and predicts the number of bike rentals in a given region.</p>"},{"location":"advanced-user-guide/workflows/bike-example/#import-a-wings-domain","title":"Import a WINGS domain","text":"<p>This section will be learn about how to create a workflow using Wings. To do that, we have prepared a Wings domain using the previous code. </p> <p>Info</p> <p>Domains serve as workspaces in which you can organize your projects. Creating different domains for various tasks helps to prevent confusing components and makes elements of the workflow easier to find. Domains can be thought of as analogous to windows within a web browser and related templates are like related tabs within a window. </p> <p>To import a Wings domain, open \"Manage Domain\" page from the Portal Navigation Menu.</p> <p></p> <p>Click on \"Import Domain\" to import an existing domain</p> <p></p> <p>We can either give a pointer to an existing domain Zip file, or upload one. Here we are pointing to a domain zip file present in the wings servers. Other domains can be found here: https://raw.githubusercontent.com/KnowledgeCaptureAndDiscovery/DISK-UI/main/docs/domains/bikes.zip</p>"},{"location":"advanced-user-guide/workflows/bike-example/#check-the-workflow-component","title":"Check the Workflow component","text":"<p>Info</p> <p>Workflow component - A workflow component can be used as a step in the workflow. It is either 1) an executable software component that is encapsulated and can be directly executed, or 2) a class of software components (also called an abstract component) whose instances are executable software components. </p> <p>Go to your WINGS instance and follow the next steps:</p> <p></p> <p>To check the component, click on the component name.</p> <p></p> <p>Now this component's IO (Inputs/Outputs) can be viewed.</p> <p></p> <p>This component has:</p> <ul> <li>one input file (?weatherRecordCsvFile), this input expects one or multiple CSV files with the following columns: season,mnth,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,cnt</li> <li>three inputs parameters (?weatherSensor1, ?weatherSensor2, ?weatherSensor3) that are the weather sensors used in the prediction.</li> <li>two outputs file (?p_value, ?summary) that are the model predictions and the summary of the model.</li> </ul>"},{"location":"advanced-user-guide/workflows/bike-example/#check-the-component-code","title":"Check the component code","text":"<p>Click on the \"Code\" button to view the component code.</p>"},{"location":"advanced-user-guide/workflows/bike-example/#check-the-workflow","title":"Check the workflow","text":"<p>You can browse and run workflows that are pre-defined in the system. You do this by selecting \"Run Workflows\" under the Analysis Tab. </p> <p></p> <p>In this tab, you can see the list of workflows that are available in the system and DISK or you can run them.</p> <p>You will be see the example workflow created by us called: \"linearRegressionBikesRental\". This workflow run the component described previously.</p> <p></p>"},{"location":"developer-guide/","title":"Overview","text":"<p>Note</p> <p>You probably don't want to be reading this section of the docs.</p> <p>This part of the manual is aimed at people wanting to develop third-party adapters that interact with DISK, e.g.</p> <ul> <li>A new workflow system</li> <li>A new data source</li> </ul>"},{"location":"developer-guide/architecture/","title":"DISK API adapters","text":"<p>The DISK System can obtain data from different data repositories and send runs to different workflow systems.</p> <p>Each data repository must have an implemented Data Adapter to transform his API responses to structures that DISK can recognize. The same is true for each method provider (workflow systems), a Method Adapter must be written to interact with the external API.</p> <p>To understand how this is done we could look how the data interacts in the system.</p> <p></p> <p>DISK provides an abstract classes to implement both, method adapters and data adapters. Check their respective page for a detailed explanation on how to create a new adapter.</p> <p>The current implementation of the DISK system includes two method adapters: WINGS Workflow System adapter and AirFlow adapter (WIP); And one data adapter: the Semantic Media Wiki adapter.</p>"},{"location":"developer-guide/architecture/#implemented-adapters","title":"Implemented adapters","text":""},{"location":"developer-guide/architecture/#wings-adapter","title":"WINGS Adapter","text":"<ul> <li>List workflows.</li> <li>Create new executions with parameters and files.</li> <li>Stores output files.</li> <li>Provides a <code>SPARQL</code> endpoint and stores executions on <code>RDF</code>.</li> </ul>"},{"location":"developer-guide/architecture/#airflow-adapter","title":"AirFlow Adapter","text":"<ul> <li>WIP</li> </ul>"},{"location":"developer-guide/architecture/#semantic-media-wiki-adapter","title":"Semantic Media Wiki Adapter","text":"<ul> <li>Provides a <code>SPARQL</code> endpoint to search for data.</li> <li>SMW can be configured to use the same ontologies as DISK.</li> <li>SMW can be used to add files and metadata.</li> </ul>"},{"location":"developer-guide/contributing/","title":"Contributing","text":"<p>DISK system is an open source project and we welcome contributions from the community. We are grateful for any help you can provide.</p>"},{"location":"developer-guide/contributing/#repository","title":"Repository","text":"<p>The source code for DISK system is hosted on GitHub. You can find the repository at:</p> <ul> <li>UI</li> <li>Backend</li> </ul>"},{"location":"developer-guide/data-adapter/","title":"Data Adapter","text":"<p>A DISK Data adapter is the implementation of the <code>DataAdapter</code> abstract class (show at the end). This adapters are used to add data into the DISK System.</p> <p>The data adapter must be able to perform at least the following operations:</p> <ul> <li>Process a data query and obtain results (files and parameters).</li> <li>Obtain <code>SPARQL</code> results to use as options.</li> <li>Get information about files in the repository (hashes, dates, etc).</li> </ul> <pre><code>public abstract class DataAdapter {\nprivate String endpointUrl, name, username, password, prefix, namespace;\n\npublic DataAdapter (String URI, String name, String username, String password);\n\npublic String getEndpointUrl ();\npublic String getName ();\nprotected String getUsername ();\nprotected String getPassword ();\n\npublic void setPrefix (String prefix, String namespace);\npublic String getPrefix ();\npublic String getNamespace ();\n\npublic abstract List&lt;DataResult&gt; query (String queryString);\n\n//This data query must return two variable names:\nstatic public String VARURI = \"uri\";\nstatic public String VARLABEL = \"label\";\npublic abstract List&lt;DataResult&gt; queryOptions (String varname, String constraintQuery);\n\n// file -&gt; hash\npublic abstract Map&lt;String, String&gt; getFileHashes (List&lt;String&gt; dsurls);\n\n// Check that a LOI is correctly configured for this adapter\npublic abstract boolean validateLOI (LineOfInquiry loi, Map&lt;String, String&gt; values);\n}\n</code></pre>"},{"location":"developer-guide/method-adapter/","title":"Method Adapter","text":"<p>A DISK Method adapter is the implementation of the <code>MethodAdapter</code> abstract class (at the end). This adapters are used to gain control of the workflow system from DISK.</p> <p>The method adapter must be able to perform at least the following operations:</p> <ul> <li>Get a list of methods</li> <li>Send a workflow execution </li> <li>Monitor workflows</li> </ul> <pre><code>public abstract class MethodAdapter {\npublic MethodAdapter () {}\n\npublic List&lt;Method&gt; ListMethods ();\npublic Method GetMethodInfo (String methodid);\npublic boolean RunMethod (Method method);\n\n// Check that a LOI is correctly configured for this adapter\npublic abstract boolean validateLOI (LineOfInquiry loi, Map&lt;String, String&gt; values);\n}\n</code></pre>"},{"location":"developer-guide/rest/","title":"DISK REST API","text":"<p>The main resources of DISK are exposed through the REST API. Common REST operations are available, but some may be restricted to authenticated users.</p> <p>Each resource can be listed (<code>GET</code>), but creating (<code>POST</code>) or editing (<code>PUT</code>) needs authentication.</p>"},{"location":"developer-guide/rest/#authentication","title":"Authentication","text":"<p>To edit the data on the DISK REST API you need an account on our login system. You could get an access token with:</p> <pre><code>curl -d 'client_id=enigma-disk' -d 'username=xxx' -d 'password=xxx' -d 'grant_type=password' \\\n     'https://auth.mint.isi.edu/auth/realms/production/protocol/openid-connect/token'\n</code></pre> <p>On each authorized request you must add the obtained access token and added to the request header:</p> <pre><code>Authorization: Bearer &lt;your_token&gt;\n</code></pre>"},{"location":"developer-guide/rest/#hypotheses","title":"Hypotheses","text":"<p>Hypotheses represents a question to be solve.</p> <ul> <li>List resources: <code>GET disk-server/hypotheses</code></li> <li>Get specific resource <code>GET disk-server/hypotheses/{id}</code></li> <li>Edit specific resource <code>PUT disk-server/hypotheses/{id}</code></li> <li>Create a new resource <code>POST disk-server/hypotheses</code></li> </ul> <p>With the following json schema:</p> <pre><code>{\n\"id\":string,\n\"name\":string,\n\"description\":string,\n\"dateCreated\":timestamp,\n\"dateModified\":timestamp,\n\"author\":string (email),\n\"notes\":string,\n\"parentId\":string,\n\"question\":string (QuestionURI),\n\"questionBindings\":[\n{\n\"variable\":string (VariableURI),\n\"binding\":string (value),\n\"collection\":boolean\n},\n... ],\n\"graph\":{\n\"triples\":[\n{\n\"subject\":string (subject URI),\n\"predicate\":string (subject URI),\n\"object\":{\n\"type\":string (LITERAL or URI),\n\"value\":string (value),\n\"datatype\":string (datatype if LITERAL)\n}\n},\n...\n]\n}\n}\n</code></pre>"},{"location":"developer-guide/rest/#line-of-inquiry","title":"Line of Inquiry","text":"<p>Lines of inquiry represents a method to get data and solve a type of question</p> <ul> <li>List resources: <code>GET disk-server/lois</code></li> <li>Get specific resource <code>GET disk-server/lois/{id}</code></li> <li>Edit specific resource <code>PUT disk-server/lois/{id}</code></li> <li>Create a new resource <code>POST disk-server/lois</code></li> </ul> <p>With the following json schema:</p> <pre><code>{\n\"id\":string,\n\"name\":string,\n\"description\":string,\n\"hypothesisQuery\":string,\n\"dataQuery\":string,\n\"notes\":string,\n\"author\":string,\n\"dateCreated\":timestamp,\n\"dateModified\":timestamp,\n\"relevantVariables\":string,\n\"explanation\":string,\n\"dataSource\":string,\n\"question\":string (question URI),\n\"workflows\":[\n{\n\"workflow\":string,\n\"workflowLink\":string,\n\"bindings\":[\n{\n\"variable\":string,\n\"binding\":string,\n\"collection\":boolean\n},\n...\n],\"parameters\":[\n{\n\"variable\":string,\n\"binding\":string,\n\"collection\":boolean\n},\n...\n],\n\"optionalParameters\":[\n{\n\"variable\":string,\n\"binding\":string,\n\"collection\":boolean\n},\n...\n],\n\"run\":{\n\"id\":string,\n\"link\":string,\n\"status\":string,\n\"outputs\":string[],\n\"files\":string[],\n\"startDate\":timestamp,\n\"endDate\":timestamp\n}\n}\n],\n\"metaWorkflows\":[same as workflow]\n}\n</code></pre>"},{"location":"developer-guide/rest/#triggered-line-of-inquiry","title":"Triggered Line of Inquiry","text":"<p>A Triggered Line of Inquiry represents the execution of a Line of Inquiry that matches a hypothesis.</p> <ul> <li>List resources: <code>GET disk-server/lois</code></li> <li>Get specific resource <code>GET disk-server/lois/{id}</code></li> <li>Edit specific resource <code>PUT disk-server/lois/{id}</code></li> <li>Create a new resource <code>POST disk-server/lois</code></li> </ul> <p>With the following json schema:</p> <pre><code>{\n\"id\":string,\n\"name\":string,\n\"description\":string,\n\"status\":string,\n\"loiId\":string,\n\"parentHypothesisId\":string,\n\"resultingHypothesisIds\":string[],\n\"author\":string,\n\"notes\":string,\n\"dateCreated\":timestamp,\n\"dateModified\":timestamp,\n\"dataQuery\":string,\n\"relevantVariables\":string,\n\"explanation\":string,\n\"dataSource\":string,\n\"workflows\":[\n{\n\"workflow\":string,\n\"workflowLink\":string,\n\"bindings\":[\n{\n\"variable\":string,\n\"binding\":string,\n\"collection\":boolean\n},\n...\n],\n\"parameters\":[\n{\n\"variable\":string,\n\"binding\":string,\n\"collection\":boolean\n},\n...\n],\n\"optionalParameters\":[\n{\n\"variable\":string,\n\"binding\":string,\n\"collection\":boolean\n},\n...\n],\n\"run\":{\n\"id\":string,\n\"link\":string,\n\"status\":string,\n\"outputs\":string[],\n\"files\":string[],\n\"startDate\":timestamp,\n\"endDate\":timestamp\n}\n}\n],\n\"metaWorkflows\":Workflow[],\n\"inputFiles\":string[],\n\"outputFiles\":string[],\n\"confidenceValue\":double\n}\n</code></pre>"},{"location":"user-guide/","title":"Overview","text":"<p>This documentation is for users who want to create hypotheses that can be tested automatically by DISK.</p>"},{"location":"user-guide/test-hypothesis/","title":"Testing a New Hypothesis","text":"<p>DISK can test your new hypothesis by triggering a Line of Inquiry (LOI) that matches it.  This will happen automatically, and DISK will show you the results.  But in case you are curious, we show you next how you can browse the Lines of Inquiry defined in DISK.</p>"},{"location":"user-guide/test-hypothesis/#browsing-lois","title":"Browsing LOIs","text":"<p>To view LOIs associated with a hypothesis template, go to the Hypothesis tab. The LOIs are listed under the Hypothesis template that they match.  </p> <p>Info</p> <p>Lines of inquiry are created by Advanced Users who are familiar with advanced features of DISK.</p> <p>This example shows the LOIs associated with two hypotheses:</p> <p></p>"},{"location":"user-guide/test-hypothesis/#executing-lois","title":"Executing LOIs","text":"<p>You don't have to ask DISK to execute LOIs.  LOIs are executed automatically when you add a new hypothesis or question.</p> <p>The LOIs that match your new hypothesis will be triggered.  When an LOI is triggered, the following occurs:</p> <ul> <li>A data query will be executed to retrieve relevant data</li> <li>One or more workflows will be executed to analyze the data</li> <li>A meta-workflow will be executed to assemble the results of all the workflows </li> </ul>"},{"location":"user-guide/test-hypothesis/#checking-results","title":"Checking Results","text":"<p>When you select an LOI name, you can see all the workflow executions, including their individual results.</p> <p>In the following image, you can see two workflow executions associated with the LOI. The first one is using 10 input datasets, generating 2 outputs and showing a resulting p-value of 0.838.  The second one is using 56 input datasets, generating 2 outputs and showing a resulting p-value of 0.776.</p> <p></p>"},{"location":"user-guide/test-hypothesis/#getting-the-execution-provenance","title":"Getting the Execution Provenance","text":"<p>All the LOI and workflow executions are recorded in detail.  To display the execution provenance, you can click the Date of the execution.</p> <p>The following image shows the execution provenance for the hypothesis, along with a table that summarizes key metadata of the input datasets used.</p> <p></p>"},{"location":"user-guide/test-hypothesis/#updating-the-results","title":"Updating the Results","text":"<p>The LOI will be triggered again when new datasets become available in the data source.  DISK will do this automatically.  </p> <p>You can view the new executions and the updated results.</p>"},{"location":"user-guide/test-hypothesis/#next-steps","title":"Next steps","text":"<p>You can learn more about what Advanced Users can do in DISK.</p>"},{"location":"user-guide/write-hypothesis/","title":"Specifying A New Hypothesis","text":"<p>A user can start to add a new hypothesis by selecting Create Hypothesis.</p> <p></p> <p>We are going to create a new question to see what weather variables affect the number bikes rented.</p>"},{"location":"user-guide/write-hypothesis/#selecting-a-hypothesis-or-question-template","title":"Selecting a Hypothesis or Question Template","text":"<p>DISK will show a menu of all the hypothesis and question templates that are defined in the system.  This means that there are Lines of Inquiry that DISK can use to answer the types of questions that fit those templates.</p> <p>You can display the questions available by clicking on the Select Hypothesis Question drop down list. Then, select a question from the list.</p> <p>Info</p> <p>The question templates and Lines of Inquiry are created by Advanced Users.</p>"},{"location":"user-guide/write-hypothesis/#creating-a-specific-hypothesis","title":"Creating a Specific Hypothesis","text":"<p>To create a specific hypothesis or question, you need to fill the question template by selecting from the menus shown.</p> <p>In our bike example, we can create questions about whether the number of bikes rented is associated with the weather variables that we are investigating.</p> <p></p>"},{"location":"user-guide/write-hypothesis/#documenting-a-new-hypothesis","title":"Documenting a New Hypothesis","text":"<p>You can fill the form to provide the following documentation:</p> <ul> <li>Hypothesis name: The name that you want to give the hypothesis.</li> <li>Hypothesis description: A brief description of the hypothesis.</li> <li>Hypothesis Notes: Any notes you want to add that will be attached to the hypothesis.</li> </ul> <p></p>"},{"location":"user-guide/write-hypothesis/#saving-your-new-hypothesis","title":"Saving Your New Hypothesis","text":"<p>Finally, you can click in the Save  button to save the hypothesis and question.</p>"},{"location":"user-guide/write-hypothesis/#next-step","title":"Next step","text":"<p>In the next step, we will show you how to find a Line of Inquiry to test your new hypothesis.</p>"}]}